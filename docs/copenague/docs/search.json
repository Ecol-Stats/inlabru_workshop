[
  {
    "objectID": "day1_practical.html",
    "href": "day1_practical.html",
    "title": "Practical 1",
    "section": "",
    "text": "Aim of this practical:  In this first practical we are going to look at some simple models\nwe are going to learn:\nDownload Practical 1 R script",
    "crumbs": [
      "Home",
      "Practical 1"
    ]
  },
  {
    "objectID": "day1_practical.html#sec-linmodel",
    "href": "day1_practical.html#sec-linmodel",
    "title": "Practical 1",
    "section": "Linear Model",
    "text": "Linear Model\nStart by loading usefull libraries:\n\nlibrary(dplyr)\nlibrary(INLA)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(inlabru)     \n# load some libraries to generate nice map plots\nlibrary(scico)\n\nAs our first example we consider a simple linear regression model with Gaussian observations \\(y_i\\sim\\mathcal{N}(\\mu_i, \\sigma^2)\\), \\(i = 1,\\dots,N\\) where \\(\\sigma^2\\) is the observation error, and the mean parameter \\(\\mu_i\\) is linked to the linear predictor through an identity function: \\[\n\\eta_i = \\mu_i = \\beta_0 + \\beta_1 x_i\n\\] where \\(x_i\\) is a covariate and \\(\\beta_0, \\beta_1\\) are parameters to be estimated.\nTo finalize the Bayesian model we need to assign a \\(\\text{Gamma}(a,b)\\) prior to the precision parameter \\(\\tau = 1/\\sigma^2\\) and two independent Gaussian priors with mean \\(0\\) and precision \\(\\tau_{\\beta}\\) to the regression parameters \\(\\beta_0\\) and \\(\\beta_1\\).\n\n\n\n\n\n\n Question\n\n\n\nWhat is the dimension of the hyperparameter vector and latent Gaussian field?\n\n\nAnswer\n\nThe hyperparameter vector has dimension 1, \\(\\pmb{\\theta} = (\\tau)\\) while the latent Gaussian field \\(\\pmb{u} = (\\beta_0, \\beta_1)\\) has dimension 2, \\(0\\) mean, and sparse precision matrix:\n\\[\n\\pmb{Q} = \\tau_{\\beta}\\begin{bmatrix}\n1 & 0\\\\\n0 & 1\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can write the linear predictor vector \\(\\pmb{\\eta} = (\\eta_i,\\dots,\\eta_N)\\) as\n\\[\n\\pmb{\\eta} = \\pmb{A}\\pmb{u} = \\pmb{A}_1\\pmb{u}_1 + \\pmb{A}_2\\pmb{u}_2 = \\begin{bmatrix}\n1 \\\\\n1\\\\\n\\vdots\\\\\n1\n\\end{bmatrix} \\beta_0 + \\begin{bmatrix}\nx_1 \\\\\nx_2\\\\\n\\vdots\\\\\nx_N\n\\end{bmatrix} \\beta_1\n\\]\nOur linear predictor consists then of two components.\n\n\n\nSimulate example data\n\nIn this practical we will use simulated Gaussian data to get familiar with the inlabru workflow. Moreover, we will see how to change the prior distributions both for the fixed effects \\(\\beta_0\\) and \\(\\beta_1\\) and for the hyperparameter \\(\\tau = 1/\\sigma^2\\). First, we simulate data from the model\n\\[\ny_i\\sim\\mathcal{N}(\\eta_i,0.1^2), \\ i = 1,\\dots,100\n\\]\nwith\n\\[\n\\eta_i = \\beta_0 + \\beta_1 x_i\n\\]\nwhere \\(\\beta_0 = 2\\),\\(\\beta_1 = 0.5\\) and the values of the covariate \\(x\\) are generated from an Uniform(0,1) distribution. The simulated response and covariate data are then saved in a data.frame object.\n\n\nCode\nbeta = c(1,1)\nsd_error = 1\n\nn = 100\nx = rnorm(n)\ny = beta[1] + beta[2] * x + rnorm(n, sd = sd_error)\n\ndf = data.frame(y = y, x = x)  \n\n\n\n\nFitting a linear regression model with inlabru\n\nDefining model components\nThe model has two parameters to be estimated \\(\\beta_1\\) and \\(\\beta_2\\). We need to define the two corresponding model components:\n\ncmp =  ~ Intercept(1) + beta_1(x, model = \"linear\")\n\nThe cmp object is here used to define model components. We can give them any useful names we like\n\n\n\n\n\n\nNote\n\n\n\nNote that Intercept() is one of inlabru special names and it is used to define a global intercept. You should explicitly exclude automatic intercept when not using the special Intercept name, e.g.\n\ncmp =  ~ -1 + myIntercept(1) + beta_1(x, model = \"linear\")\n\n\n\nObservation model construction\nThe next step is to construct the observation model by defining the model likelihood. The most important inputs here are the formula, the family and the data.\nThe formula defines how the components should be combined in order to define the model predictor.\n\nformula = y ~ Intercept + beta_1\n\n\n\n\n\n\n\nNote\n\n\n\nIn this case we can also use the shortcut formula = y ~ .. This will tell inlarbu that the model is linear and that it is not necessary to linearize the model and assess convergence.\n\n\nThe likelihood is defined using the bru_obs() function as follows:\n\nlik =  bru_obs(formula = y ~.,\n            family = \"gaussian\",\n            data = df)\n\nFit the model\nWe fit the model using the bru() functions which takes as input the components and the observation model:\n\nfit.lm = bru(cmp, lik)\n\nThe summary() function will give access to some basic information about model fit and estimates\n\nsummary(fit.lm)\n\ninlabru version: 2.12.0\nINLA version: 24.06.27\nComponents:\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL\nbeta_1: main = linear(x), group = exchangeable(1L), replicate = iid(1L), NULL\nLikelihoods:\n  Family: 'gaussian'\n    Tag: ''\n    Data class: 'data.frame'\n    Response class: 'numeric'\n    Predictor: y ~ .\n    Used components: effects[Intercept, beta_1], latent[]\nTime used:\n    Pre = 0.629, Running = 0.302, Post = 0.103, Total = 1.03 \nFixed effects:\n           mean    sd 0.025quant 0.5quant 0.975quant  mode kld\nIntercept 1.067 0.114      0.843    1.067      1.291 1.067   0\nbeta_1    0.923 0.120      0.688    0.923      1.158 0.923   0\n\nModel hyperparameters:\n                                         mean    sd 0.025quant 0.5quant\nPrecision for the Gaussian observations 0.784 0.111      0.582    0.778\n                                        0.975quant  mode\nPrecision for the Gaussian observations       1.02 0.768\n\nDeviance Information Criterion (DIC) ...............: 314.15\nDeviance Information Criterion (DIC, saturated) ....: 105.38\nEffective number of parameters .....................: 2.99\n\nWatanabe-Akaike information criterion (WAIC) ...: 314.41\nEffective number of parameters .................: 3.12\n\nMarginal log-Likelihood:  -176.48 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\nWe can see that both the intercept and slope and the error precision are correctly estimated. We can then plot the marginal posterior for \\(\\beta_0\\) as follows:\n\nplot(fit.lm, \"Intercept\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Task\n\n\n\nPlot the posterior marginals for \\(\\beta_1\\) and for the precision of the observation error \\(\\pi(\\tau|y)\\)\n\n\nTake hint\n\nSee the summary() output to check the names for the different model components.\n\n\n\n\nClick here to see the solution\n\n\nCode\nplot(fit.lm, \"beta_1\") +\nplot(fit.lm, \"Precision for the Gaussian observations\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Task\n\n\n\nPlot the fitted values with 95% Credible intervals.\n\n\nTake hint\n\nbru objects information about the linear predictor can be accessed through fit.lm$summary.fitted.values.\n\n\n\n\nClick here to see the solution\n\n\nCode\ndf %&gt;% mutate(post_mean = fit.lm$summary.fitted.values[1:100,\"mean\"],\n              q25 = fit.lm$summary.fitted.values[1:100,\"0.025quant\"],\n              q975 = fit.lm$summary.fitted.values[1:100,\"0.975quant\"])%&gt;%\n  ggplot()+geom_point(aes(x=x,y=y),alpha=0.5,color=\"grey40\")+\n  geom_line(aes(x=x,y=post_mean),col=2)+\n  geom_ribbon(aes(x = x, ymax = q975, ymin = q25),fill=\"tomato\", alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate model predictions\n\nNow we can take the fitted bru object and use the predict function to produce predictions given a new set of values for the model covariates or the original values used for the model fit\n\nnew_data = data.frame(x = c(df$x, runif(10)),\n                      y = c(df$y, rep(NA,10)))\npred = predict(fit.lm, new_data, ~ Intercept + beta_1)\n\n\nPlotR Code\n\n\n\n\n\n\n\nData and 95% credible intervals\n\n\n\n\n\n\n\n\nCode\npred %&gt;% ggplot() + \n  geom_point(aes(x,y), alpha = 0.3) +\n  geom_line(aes(x,mean)) +\n  geom_line(aes(x, q0.025), linetype = \"dashed\")+\n  geom_line(aes(x, q0.975), linetype = \"dashed\")+\n  xlab(\"Covariate\") + ylab(\"Observations\")",
    "crumbs": [
      "Home",
      "Practical 1"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "inlabru Workshop",
    "section": "",
    "text": "Welcome to the inlabu workshop!\nThe goal for the workshop is to …\nThe workshop is intended for … No knowledge of R-INLA is required.\nWorkshop materials in the github repository inlabru-workshop\n\n\n\nAt the end of the workshop, participants will be able to:\n\nILO1\nILO2\nILO3, etc\n\nIntended audience and level: The tutorial is intended for … No knowledge of R-INLA is required.",
    "crumbs": [
      "Home",
      "`inlabru` Workshop"
    ]
  },
  {
    "objectID": "index.html#learning-objectives-for-the-workshop",
    "href": "index.html#learning-objectives-for-the-workshop",
    "title": "inlabru Workshop",
    "section": "",
    "text": "At the end of the workshop, participants will be able to:\n\nILO1\nILO2\nILO3, etc\n\nIntended audience and level: The tutorial is intended for … No knowledge of R-INLA is required.",
    "crumbs": [
      "Home",
      "`inlabru` Workshop"
    ]
  },
  {
    "objectID": "slides/slides_1.html#course-structure-day-1",
    "href": "slides/slides_1.html#course-structure-day-1",
    "title": "inlabru workshop",
    "section": "Course Structure: Day 1",
    "text": "Course Structure: Day 1\n\n\n\n\n\n\n\n\n\nTime\nTopic\nContent\nExcercises\n\n\n\n\nXXXX am\nCore concepts\n\nLGM and INLA\ninlabru workflow\nModel selection\n\n\n\n\nXXXX am\nTemporal Models\n\nDiscrete time models\nContinuous time models"
  },
  {
    "objectID": "slides/slides_1.html#course-structure-day-2",
    "href": "slides/slides_1.html#course-structure-day-2",
    "title": "inlabru workshop",
    "section": "Course Structure: Day 2",
    "text": "Course Structure: Day 2\n\n\n\n\n\n\n\n\n\nTime\nTopic\nContent\nExcercises\n\n\n\n\nXXXX am\nIntroduction to Spatial Modelling\n\nTypes of spatial data\nSpatial data wrangling and manipulation in R (e.g, terra & sf)\nAreal processes\n\n\n\n\nXXXX am\nModelling geostatistical data\n\nSPDE & the mesh\nGeostatistical Data\nSpatial predictions"
  },
  {
    "objectID": "slides/slides_1.html#course-structure-day-3",
    "href": "slides/slides_1.html#course-structure-day-3",
    "title": "inlabru workshop",
    "section": "Course Structure: Day 3",
    "text": "Course Structure: Day 3\n\n\n\n\n\n\n\n\n\nTime\nTopic\nContent\nExcercises\n\n\n\n\nXXXX am\nSpatial Point processes\n\nSpatial point process\nDistance sampling\n\n\n\n\nXXXX am\nSpatiotemporal Models\n\nSeparable time-space models\nnon-separable space-time models"
  },
  {
    "objectID": "slides/slides_1.html#course-structure-day-4",
    "href": "slides/slides_1.html#course-structure-day-4",
    "title": "inlabru workshop",
    "section": "Course Structure: Day 4",
    "text": "Course Structure: Day 4\n\n\n\n\n\n\n\n\n\nTime\nTopic\nContent\nExcercises\n\n\n\n\nXXXX am\nMultilikelihood and Non-linear models\n\niterated inla\nlogistic growth\nCorregionalization models"
  }
]