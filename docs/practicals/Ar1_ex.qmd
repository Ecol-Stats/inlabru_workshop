---
title: "Autoregressive Models"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

## AR(1) models in `inlabru`

In this exercise we will:

-   Simulate a time series with autocorrelated errors.

-   Fit an AR(1) process with `inlabru`

-   Visualize model predictions.

Start by loading useful libraries:

```{r}
library(dplyr)
library(INLA)
library(ggplot2)
library(patchwork)
library(inlabru)     
```

Time series analysis is particularly valuable for modelling data with temporal dependence or autocorrelation, where observations taken at nearby time points tend to be more similar than those further apart.

A time series process is a stochastic process $\{X_t~|~t \in T\}$, which is a collection of random variables that are ordered in time where $T$ is the *index set* that determines the set of discrete and equally spaced time points at which the process is defined and observations are made.

Autoregressive processes allow us to account for the time dependece by regressing $X_t$ on past values $X_{t-1},\ldots,X_{t-p}$ with associated coefficients $\phi_k$ for each lag $k = 1,\ldots,p$. Thus an **autoregressive process of order** $p$, denoted AR($p$) , is given by:

$$
X_t = \phi_1 X_{t-1} + \ldots + \phi_p X_{t-p} + \varepsilon_t; ~~ \varepsilon_t \sim \mathcal{N}(0,\sigma^2_e)
$$

Consider now an univariate time series $y_t$ which evolves over time according to some autoregressive stochastic process. For example, a time series where the system follows an AR(1) process can be defined as:

$$
\begin{aligned}
y_t &\sim \mathcal{N}(\mu_t,\tau_y^{-1})\\
\eta_t &= g^{-1}(\mu_t) = \alpha + u_t \\
u_t &= \phi u_{t-1} + \delta_t ; ~~ \delta_t \sim \mathcal{N}(0,\tau_u^{-1}); ~~ t > 1 \\
x_1 &= \mathcal{N}(0,\kappa^{-1})\\
\kappa &= \tau_u (1-\phi^2)
\end{aligned}
$$

The response $y_t$ is assumed to be normal distributed with mean $\alpha + u_t$ and precision error $\tau_y$ ( here $g(\cdot)$ can be a link function that maps the linear predictor to the mean of the process). Then, the process $u_t$ follows an AR(1) process where $u_1$ is drawn from a stationary normal distribution such that $\kappa$ denotes the marginal precision for state $u_t$

The covariance matrix is then given by:

$$
\Sigma = \frac{\tau^{-1}_u}{1-\phi^2}
\begin{bmatrix}
1 & \phi & \phi^2 & \ldots & \phi^{n-1}\\
\phi & 1 & \phi & \ldots & \phi^{n-2} \\
\phi^2 & \phi & 1 & \ldots & \phi^{n-3} \\
\phi^{n-1} & \phi^{n-2} & \phi^{n-3} & \ldots & 1
\end{bmatrix}
$$

Notice that conditionally on $u_t$, the observed data $y_y$ are independent from$y_{t-1},y_{t-2}.y_{t-3},\ldots$, also the conditional distribution of $u_t$ is a markov chain such that $\pi(u_t|u_{t-1},u_{t-2},u_{t-3}) = \pi(u_t|u_{t-1})$. Thus, each time point is only conditionally dependent on the two closest time points:

$$
u_t|\mathbf{u}_{-t} \sim \mathcal{N}\left(\frac{\phi}{1-\phi^2}(u_{t-1}+u_{t+1}),\frac{\tau_u^{-1}}{1-\phi^2}\right)
$$

### Simulate example data

First, we simulate data from the model:

$$
\begin{aligned}
y_t &= \alpha + u_t + \varepsilon_t;~ \varepsilon_t \sim \mathcal{N}(0,\tau_y^{-1})\\
u_t &= \phi y_{t-1} + \delta_t; ~ \delta_t \sim \mathcal{N}(0,\tau_u^{-1})
\end{aligned}
$$

```{r}
set.seed(123)

phi = 0.8
tau_u = 10
marg.prec = tau_u * (1-phi^2) # ar1 in INLA is parametrized as marginal variance
u_t =  as.vector(arima.sim(list(order = c(1,0,0), ar = rho), 
                          n = 100,
                          sd=sqrt(1/tau_u)))
a = 1
tau_e = 5
epsilon_t = rnorm(100, sd = sqrt(1/tau_e))
y = a + u_t + epsilon_t


ts_dat <- data.frame(y =y , x= 1:100)

```

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 4
#| fig-height: 4

ggplot(ts_dat,aes(y=y,x=x))+geom_line()

```

### Fitting an AR(1) model with `inlabru`

```{r}
# Model components
cmp =  ~ -1 + alpha(1) + ut(x,model = "ar1")
# Model formula
formula = y ~ alpha + ut
# Observational model
lik =  bru_obs(formula = y ~.,
            family = "gaussian",
            data = ts_dat)
# fit the model
fit.ar1 = bru(cmp, lik)

# compare agiast the true values

data.frame(
  true = c(a,tau_e,marg.prec,phi),
  rbind(fit.ar1$summary.fixed[,c(1,3,5)],
        fit.ar1$summary.hyperpar[,c(1,3,5)])
        ) %>% round(2)

```

**Model predictions**

```{r}
pred_ar1 = predict(fit.ar1, ts_dat, ~ alpha + ut)

ggplot(pred_ar1,aes(y=mean,x=x))+
  geom_line()+
    geom_ribbon(aes(x = x, y = mean, ymin = q0.025, ymax = q0.975),
                alpha = 0.5) +
  geom_point(aes(y=y,x=x))

```
