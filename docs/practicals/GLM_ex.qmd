---
title: "Practical"
format: 
  html:
    theme:
      light: flatly
      dark: darkly
  PrettyPDF-pdf:
    keep-tex: true
    number-sections: true
embed-resources: true
editor_options: 
  chunk_output_type: console
---

## Generalized Linear Model {#sec-genlinmodel}

In this practical we will:

-   Simulate non-Gaussian data
-   Learn how to fit a generalised linear model with `inlabru`
-   Generate predictions from the model

```{r}
#| warning: false
#| message: false
#| echo: false
#| purl: false
library(dplyr)
library(INLA)
library(ggplot2)
library(patchwork)
library(inlabru)     
library(scico)
library(webexercises)
```

A generalised linear model allows for the data likelihood to be non-Gaussian. In this example we have a discrete response variable which we model using a Poisson distribution. Thus, we assume that our data $$
y_i \sim \text{Poisson}(\lambda_i)
$$ with rate parameter $\lambda_i$ which, using a log link, has associated predictor $$
\eta_i = \log \lambda_i = \beta_0 + \beta_1 x_i 
$$ with parameters $\beta_0$ and $\beta_1$, and covariate $x$. This is identical in form to the predictor in @sec-linmodel. The only difference is now we must specify a different data likelihood.

### **Simulate example data**

This code generates 100 samples of covariate `x` and data `y`.

```{r}
#| code-summary: "Simulate Data from a GLM"
set.seed(123)
n = 100
beta = c(1,1)
x = rnorm(n)
lambda = exp(beta[1] + beta[2] * x)
y = rpois(n, lambda  = lambda)
df = data.frame(y = y, x = x)  
```

### Fitting a GLM in `inlabru`

------------------------------------------------------------------------

**Define model components and likelihood**

Since the predictor is the same as @sec-linmodel, we can use the same component definition:

```{r}
#| code-summary: "GLM components"

cmp =  ~ -1 + beta_0(1) + beta_1(x, model = "linear")
```

However, when building the observation model likelihood we must now specify the Poisson likelihood using the `family` argument (the default link function for this family is the $\log$ link).

```{r}
#| code-summary: "GLM likelihood"

lik =  bru_obs(formula = y ~.,
            family = "poisson",
            data = df)
```

**Fit the model**

Once the likelihood object is constructed, fitting the model is exactly the same process as in @sec-linmodel.

```{r}
#| code-summary: "Fit a GLM"
fit_glm = bru(cmp, lik)
```

And model summaries can be viewed using

```{r }
#| code-summary: "GLM summaries"
summary(fit_glm)
```

### Generate model predictions

------------------------------------------------------------------------

To generate new predictions we must provide a data frame that contains the covariate values for $x$ at which we want to predict.

This code block generates predictions for the data we used to fit the model (contained in `df$x`) as well as 10 new covariate values sampled from a uniform distribution `runif(10)`.

```{r get_predictions_glm}
#| code-summary: "Predcited values for Poisson GLM"
 
# Define new data, set to NA the values for prediction

new_data = data.frame(x = c(df$x, runif(10)),
                      y = c(df$y, rep(NA,10)))

# Define predictor formula
pred_fml <- ~ exp(beta_0 + beta_1)

# Generate predictions
pred_glm <- predict(fit_glm, new_data, pred_fml)
```

Since we used a log link (which is the default for `family = "poisson"`), we want to predict the exponential of the predictor. We specify this using a general `R` expression using the formula syntax.

::: callout-note
Note that the `predict` function will call the component names (i.e. the "labels") that were decided when defining the model.
:::

Since the component definition is looking for a covariate named $x$, all we need to provide is a data frame that contains one, and the software does the rest.

::: panel-tabset
## Plot

```{r}
#| echo: false
#| code-summary: "Plot GLM predicted values"
#| fig-cap: Data and 95% credible intervals
#| fig-align: center
#| fig-width: 4
#| fig-height: 4
#| warning: false

pred_glm %>% ggplot() + 
  geom_point(aes(x,y), alpha = 0.3) +
  geom_line(aes(x,mean)) +
    geom_ribbon(aes(x = x, ymax = q0.975, ymin = q0.025),fill = "tomato", alpha = 0.3)+
  geom_line(aes(x, q0.025), linetype = "dashed")+
  geom_line(aes(x, q0.975), linetype = "dashed")+
  xlab("Covariate") + ylab("Observations (counts)")
```

## R Code

```{r}
#| eval: false
#| code-summary: "Plot GLM predicted values"
#| purl: false

pred_glm %>% ggplot() + 
  geom_point(aes(x,y), alpha = 0.3) +
  geom_line(aes(x,mean)) +
    geom_ribbon(aes(x = x, ymax = q0.975, ymin = q0.025),fill = "tomato", alpha = 0.3)+
  xlab("Covariate") + ylab("Observations (counts)")
```
:::

::: {.callout-warning icon="false"}
## {{< bi pencil-square color=#c8793c >}}Task

Suppose a binary response such that

$$
    \begin{aligned}
y_i &\sim \mathrm{Bernoulli}(\psi_i)\\
\eta_i &= \mathrm{logit}(\psi_i) = \alpha_0 +\alpha_1 \times w_i 
\end{aligned}
$$ Using the following simulated data, use `inlabru` to fit the logistic regression above. Then, plot the predictions for the data used to fit the model along with 10 new covariate values

```{r}
#| code-summary: "GLM Task"
set.seed(123)
n = 100
alpha = c(0.5,1.5)
w = rnorm(n)
psi = plogis(alpha[1] + alpha[2] * w)
y = rbinom(n = n, size = 1, prob =  psi) # set size = 1 to draw binary observations
df_logis = data.frame(y = y, w = w)  
```

Here we use the logit link function $\mathrm{logit}(x) = \log\left(\frac{x}{1-x}\right)$ (`plogis()` function in R) to link the linear predictor to the probabilities $\psi$.

`r hide("Take hint")`

You can set `family = "binomial"` for binary responses and the `plogis()` function for computing the predicted values.

::: callout-note
The Bernoulli distribution is equivalent to a $\mathrm{Binomial}(1, \psi)$ pmf. If you have proportional data (e.g. no. successes/no. trials) you can specify the number of events as your response and then the number of trials via the `Ntrials = n` argument of the `bru_obs` function (where `n` is the known vector of trials in your data set).
:::

`r unhide()`

```{r}
#| webex.hide: "Click here to see the solution"
#| code-fold: show
#| purl: false
#| warning: false
#| message: false
#| fig-align: center
#| fig-width: 4
#| fig-height: 4


# Model components
cmp_logis =  ~ -1 + alpha_0(1) + alpha_1(w, model = "linear")
# Model likelihood
lik_logis =  bru_obs(formula = y ~.,
            family = "binomial",
            data = df_logis)
# fit the model
fit_logis <- bru(cmp_logis,lik_logis)

# Define data for prediction
new_data = data.frame(w = c(df_logis$w, runif(10)),
                      y = c(df_logis$y, rep(NA,10)))
# Define predictor formula
pred_fml <- ~ plogis(alpha_0 + alpha_1)

# Generate predictions
pred_logis <- predict(fit_logis, new_data, pred_fml)

# Plot predictions
pred_logis %>% ggplot() + 
  geom_point(aes(w,y), alpha = 0.3) +
  geom_line(aes(w,mean)) +
    geom_ribbon(aes(x = w, ymax = q0.975, ymin = q0.025),fill = "tomato", alpha = 0.3)+
  xlab("Covariate") + ylab("Observations")

```
:::
